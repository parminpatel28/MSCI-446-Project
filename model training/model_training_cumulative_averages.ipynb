{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing Helper Functions\n",
    "from helper_functions import drop_extraneous_col\n",
    "# Recursive Feature Elimination with Cross-Validation\n",
    "from sklearn.feature_selection import RFECV\n",
    "# Time Series Split and GridSearchCV, where GridSearchCV is for hyperparameter tuning\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, cross_validate, RandomizedSearchCV\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Standard Scalar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, recall_score, precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "# Logistic Regression, Ridge Classifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "# Support Vector Machine (SVM)\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Cumulative Averages DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team0</th>\n",
       "      <th>team1</th>\n",
       "      <th>winner</th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>team0_encoded</th>\n",
       "      <th>team1_encoded</th>\n",
       "      <th>restDays_team0</th>\n",
       "      <th>restDays_team1</th>\n",
       "      <th>mp_cumulative_team0</th>\n",
       "      <th>...</th>\n",
       "      <th>blk%_cumulative_team1</th>\n",
       "      <th>tov%_cumulative_team0</th>\n",
       "      <th>tov%_cumulative_team1</th>\n",
       "      <th>ortg_cumulative_team0</th>\n",
       "      <th>ortg_cumulative_team1</th>\n",
       "      <th>drtg_cumulative_team0</th>\n",
       "      <th>drtg_cumulative_team1</th>\n",
       "      <th>ft/fga_cumulative_team0</th>\n",
       "      <th>ft/fga_cumulative_team1</th>\n",
       "      <th>team1_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLE</td>\n",
       "      <td>MIL</td>\n",
       "      <td>CLE</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>102.700000</td>\n",
       "      <td>110.400000</td>\n",
       "      <td>99.700000</td>\n",
       "      <td>102.200000</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.329000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAL</td>\n",
       "      <td>PHO</td>\n",
       "      <td>LAL</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>86.900000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>125.600000</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSW</td>\n",
       "      <td>NOP</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>118.600000</td>\n",
       "      <td>97.600000</td>\n",
       "      <td>119.600000</td>\n",
       "      <td>110.400000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORL</td>\n",
       "      <td>BRK</td>\n",
       "      <td>BRK</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>110.300000</td>\n",
       "      <td>115.700000</td>\n",
       "      <td>103.600000</td>\n",
       "      <td>123.600000</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOS</td>\n",
       "      <td>PHI</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.950000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>100.950000</td>\n",
       "      <td>110.300000</td>\n",
       "      <td>106.550000</td>\n",
       "      <td>115.100000</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8350</th>\n",
       "      <td>MIL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>241.119403</td>\n",
       "      <td>...</td>\n",
       "      <td>11.938235</td>\n",
       "      <td>10.864179</td>\n",
       "      <td>10.339706</td>\n",
       "      <td>119.949254</td>\n",
       "      <td>124.129412</td>\n",
       "      <td>116.650746</td>\n",
       "      <td>112.086765</td>\n",
       "      <td>0.221627</td>\n",
       "      <td>0.189853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8351</th>\n",
       "      <td>PHI</td>\n",
       "      <td>PHO</td>\n",
       "      <td>PHO</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>240.735294</td>\n",
       "      <td>...</td>\n",
       "      <td>10.926471</td>\n",
       "      <td>10.083824</td>\n",
       "      <td>12.583824</td>\n",
       "      <td>117.983824</td>\n",
       "      <td>118.973529</td>\n",
       "      <td>115.505882</td>\n",
       "      <td>116.622059</td>\n",
       "      <td>0.229985</td>\n",
       "      <td>0.231632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8352</th>\n",
       "      <td>MIA</td>\n",
       "      <td>CLE</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.384615</td>\n",
       "      <td>...</td>\n",
       "      <td>8.794118</td>\n",
       "      <td>10.978462</td>\n",
       "      <td>11.560294</td>\n",
       "      <td>114.193846</td>\n",
       "      <td>116.600000</td>\n",
       "      <td>113.412308</td>\n",
       "      <td>112.476471</td>\n",
       "      <td>0.216354</td>\n",
       "      <td>0.183294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8353</th>\n",
       "      <td>LAC</td>\n",
       "      <td>POR</td>\n",
       "      <td>LAC</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.373134</td>\n",
       "      <td>...</td>\n",
       "      <td>8.408955</td>\n",
       "      <td>11.274627</td>\n",
       "      <td>12.708955</td>\n",
       "      <td>120.468657</td>\n",
       "      <td>110.244776</td>\n",
       "      <td>116.623881</td>\n",
       "      <td>118.516418</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>0.192925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8354</th>\n",
       "      <td>MEM</td>\n",
       "      <td>GSW</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>241.449275</td>\n",
       "      <td>...</td>\n",
       "      <td>8.249254</td>\n",
       "      <td>12.889855</td>\n",
       "      <td>11.946269</td>\n",
       "      <td>108.060870</td>\n",
       "      <td>118.385075</td>\n",
       "      <td>114.791304</td>\n",
       "      <td>116.868657</td>\n",
       "      <td>0.187797</td>\n",
       "      <td>0.181910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8355 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team0 team1 winner  season        date  team0_encoded  team1_encoded  \\\n",
       "0      CLE   MIL    CLE    2018  2017-10-20              6             10   \n",
       "1      LAL   PHO    LAL    2018  2017-10-20             25             24   \n",
       "2      GSW   NOP    GSW    2018  2017-10-20             21             30   \n",
       "3      ORL   BRK    BRK    2018  2017-10-20             15              4   \n",
       "4      BOS   PHI    BOS    2018  2017-10-20              2              5   \n",
       "...    ...   ...    ...     ...         ...            ...            ...   \n",
       "8350   MIL   BOS    BOS    2024  2024-03-20             10              2   \n",
       "8351   PHI   PHO    PHO    2024  2024-03-20              5             24   \n",
       "8352   MIA   CLE    MIA    2024  2024-03-20             11              6   \n",
       "8353   LAC   POR    LAC    2024  2024-03-20             22             17   \n",
       "8354   MEM   GSW    GSW    2024  2024-03-20             28             21   \n",
       "\n",
       "      restDays_team0  restDays_team1  mp_cumulative_team0  ...  \\\n",
       "0                2.0             1.0           240.000000  ...   \n",
       "1                0.0             1.0           240.000000  ...   \n",
       "2                2.0             1.0           240.000000  ...   \n",
       "3                1.0             1.0           240.000000  ...   \n",
       "4                1.0             1.0           240.000000  ...   \n",
       "...              ...             ...                  ...  ...   \n",
       "8350             2.0             1.0           241.119403  ...   \n",
       "8351             1.0             2.0           240.735294  ...   \n",
       "8352             1.0             1.0           240.384615  ...   \n",
       "8353             2.0             1.0           240.373134  ...   \n",
       "8354             1.0             1.0           241.449275  ...   \n",
       "\n",
       "      blk%_cumulative_team1  tov%_cumulative_team0  tov%_cumulative_team1  \\\n",
       "0                  6.300000              15.300000              14.400000   \n",
       "1                 12.100000              15.800000              14.200000   \n",
       "2                 19.000000              16.000000              15.600000   \n",
       "3                  2.900000              12.000000              15.600000   \n",
       "4                  8.000000               9.950000              14.400000   \n",
       "...                     ...                    ...                    ...   \n",
       "8350              11.938235              10.864179              10.339706   \n",
       "8351              10.926471              10.083824              12.583824   \n",
       "8352               8.794118              10.978462              11.560294   \n",
       "8353               8.408955              11.274627              12.708955   \n",
       "8354               8.249254              12.889855              11.946269   \n",
       "\n",
       "      ortg_cumulative_team0  ortg_cumulative_team1  drtg_cumulative_team0  \\\n",
       "0                102.700000             110.400000              99.700000   \n",
       "1                 86.900000              77.000000             102.000000   \n",
       "2                118.600000              97.600000             119.600000   \n",
       "3                110.300000             115.700000             103.600000   \n",
       "4                100.950000             110.300000             106.550000   \n",
       "...                     ...                    ...                    ...   \n",
       "8350             119.949254             124.129412             116.650746   \n",
       "8351             117.983824             118.973529             115.505882   \n",
       "8352             114.193846             116.600000             113.412308   \n",
       "8353             120.468657             110.244776             116.623881   \n",
       "8354             108.060870             118.385075             114.791304   \n",
       "\n",
       "      drtg_cumulative_team1  ft/fga_cumulative_team0  ft/fga_cumulative_team1  \\\n",
       "0                102.200000                 0.253000                 0.329000   \n",
       "1                125.600000                 0.154000                 0.146000   \n",
       "2                110.400000                 0.238000                 0.304000   \n",
       "3                123.600000                 0.244000                 0.309000   \n",
       "4                115.100000                 0.168500                 0.151000   \n",
       "...                     ...                      ...                      ...   \n",
       "8350             112.086765                 0.221627                 0.189853   \n",
       "8351             116.622059                 0.229985                 0.231632   \n",
       "8352             112.476471                 0.216354                 0.183294   \n",
       "8353             118.516418                 0.216194                 0.192925   \n",
       "8354             116.868657                 0.187797                 0.181910   \n",
       "\n",
       "      team1_winner  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  \n",
       "...            ...  \n",
       "8350             1  \n",
       "8351             1  \n",
       "8352             0  \n",
       "8353             0  \n",
       "8354             1  \n",
       "\n",
       "[8355 rows x 76 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df  = pd.read_csv('csvs/cumulative_averages.csv')\n",
    "drop_extraneous_col(training_df)\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataframe into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "undesired_columns = ['team0', 'team1', 'winner', 'season', 'date', 'team1_winner']\n",
    "# We decided to train from the 2018 season to the 2023 season\n",
    "training_seasons = [2018,2019,2020,2021,2022,2023]\n",
    "# Splitting the dataframe into train and test\n",
    "X_train = training_df[training_df['season'].isin(training_seasons)].drop(undesired_columns, axis=1)\n",
    "X_test = training_df[training_df['season'] == 2024].drop(undesired_columns, axis=1)\n",
    "y_train = training_df[training_df['season'].isin(training_seasons)]['team1_winner']\n",
    "y_test = training_df[training_df['season'] == 2024]['team1_winner']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in X_train: 7348\n",
      "Observations in y_train: 7348\n",
      "Observations in X_test: 1007\n",
      "Observations in y_test: 1007\n"
     ]
    }
   ],
   "source": [
    "# Double checking the shapes of the training and testing dataframes\n",
    "\n",
    "print(f'Observations in X_train: {X_train.shape[0]}')\n",
    "print(f'Observations in y_train: {y_train.shape[0]}')\n",
    "\n",
    "print(f'Observations in X_test: {X_test.shape[0]}')\n",
    "print(f'Observations in y_test: {y_test.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scalar = StandardScaler()\n",
    "X_train = std_scalar.fit_transform(X_train)\n",
    "X_test = std_scalar.fit_transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Type of Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the type of cross validation\n",
    "tscv = TimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Results DataFrame to Store Training and Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Model', 'Training Accuracy', 'Validation Accuracy',\n",
    "                             'Training Precision', 'Validation Precision',\n",
    "                             'Training Recall ', 'Validation Recall',\n",
    "                             'Training F1', 'Validation F1',\n",
    "                             'Training ROC_AUC', 'Validation ROC_AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the Logistic Regresion Model\n",
    "model_lr = LogisticRegression(solver='saga', max_iter=5000, random_state=42)\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_lr = RFECV(estimator = model_lr, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_lr.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_lr.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(estimator=model_lr, param_grid=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "grid_search_lr.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_lr = grid_search_lr.cv_results_\n",
    "\n",
    "new_row_data = ['Logistic Regression']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_lr[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_lr[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_lr[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the RandomForestClassifier Model\n",
    "model_rfc = RandomForestClassifier(random_state=42)\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_rfc = RFECV(estimator = model_rfc, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_rfc.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_rfc.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],       # Number of trees in the forest.\n",
    "    'max_depth': [None, 10, 20, 30],        # Maximum depth of the tree.\n",
    "    'min_samples_split': [2, 5, 10],        # Minimum number of samples required to split an internal node.\n",
    "    'min_samples_leaf': [1, 2, 4], \n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "random_search_rfc = RandomizedSearchCV(estimator=model_rfc, n_iter=100, param_distributions=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "random_search_rfc.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_rfc = random_search_rfc.cv_results_\n",
    "\n",
    "new_row_data = ['Random Forest Classifier']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_rfc[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_rfc[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_rfc[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the XGB Classifier Model\n",
    "model_xgb = XGBClassifier(objective='binary:logistic')\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_xgb = RFECV(estimator = model_xgb, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_xgb.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_xgb.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'min_child_weight': [1, 3, 5, 7]\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(estimator=model_xgb, n_iter=100, param_distributions=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "random_search_xgb.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_xgb = random_search_xgb.cv_results_\n",
    "\n",
    "new_row_data = ['XGB Classifier']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_xgb[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_xgb[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_xgb[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the Ridge Classifier Model\n",
    "model_rc = RidgeClassifier(solver='saga', max_iter=5000, random_state=42)\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_rc = RFECV(estimator = model_rc, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_rc.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_rc.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "grid_search_rc = GridSearchCV(estimator=model_rc, param_grid=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "grid_search_rc.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_rc = grid_search_rc.cv_results_\n",
    "\n",
    "new_row_data = ['Ridge Classifier']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_rc[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_rc[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_rc[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the Support Vector Machine Model\n",
    "model_svm = LinearSVC(max_iter=5000, random_state=42, dual='auto')\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_svm = RFECV(estimator = model_svm, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_svm.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_svm.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'],  # Penalty\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(estimator=model_svm, param_grid=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "grid_search_svm.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_svm = grid_search_svm.cv_results_\n",
    "\n",
    "new_row_data = ['Linear SVC']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_svm[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_svm[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_svm[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Validation Precision</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Validation Recall</th>\n",
       "      <th>Training F1</th>\n",
       "      <th>Validation F1</th>\n",
       "      <th>Training ROC_AUC</th>\n",
       "      <th>Validation ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.653162</td>\n",
       "      <td>0.636438</td>\n",
       "      <td>0.668556</td>\n",
       "      <td>0.662558</td>\n",
       "      <td>0.899976</td>\n",
       "      <td>0.89268</td>\n",
       "      <td>0.736639</td>\n",
       "      <td>0.720072</td>\n",
       "      <td>0.627854</td>\n",
       "      <td>0.621808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.975172</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.946869</td>\n",
       "      <td>0.640771</td>\n",
       "      <td>0.994993</td>\n",
       "      <td>0.784625</td>\n",
       "      <td>0.978879</td>\n",
       "      <td>0.702098</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.603428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>0.736015</td>\n",
       "      <td>0.622549</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>0.640839</td>\n",
       "      <td>0.916131</td>\n",
       "      <td>0.905548</td>\n",
       "      <td>0.763848</td>\n",
       "      <td>0.722934</td>\n",
       "      <td>0.714417</td>\n",
       "      <td>0.600164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.63317</td>\n",
       "      <td>0.666682</td>\n",
       "      <td>0.660461</td>\n",
       "      <td>0.836317</td>\n",
       "      <td>0.776819</td>\n",
       "      <td>0.73317</td>\n",
       "      <td>0.701699</td>\n",
       "      <td>0.625414</td>\n",
       "      <td>0.618171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.653512</td>\n",
       "      <td>0.632026</td>\n",
       "      <td>0.667506</td>\n",
       "      <td>0.653756</td>\n",
       "      <td>0.803963</td>\n",
       "      <td>0.755788</td>\n",
       "      <td>0.728051</td>\n",
       "      <td>0.697753</td>\n",
       "      <td>0.625755</td>\n",
       "      <td>0.614282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Training Accuracy Validation Accuracy  \\\n",
       "0       Logistic Regression          0.653162            0.636438   \n",
       "1  Random Forest Classifier          0.975172               0.625   \n",
       "2            XGB Classifier          0.736015            0.622549   \n",
       "3          Ridge Classifier          0.653763             0.63317   \n",
       "4                Linear SVC          0.653512            0.632026   \n",
       "\n",
       "  Training Precision Validation Precision Training Recall  Validation Recall  \\\n",
       "0           0.668556             0.662558         0.899976           0.89268   \n",
       "1           0.946869             0.640771         0.994993          0.784625   \n",
       "2           0.869231             0.640839         0.916131          0.905548   \n",
       "3           0.666682             0.660461         0.836317          0.776819   \n",
       "4           0.667506             0.653756         0.803963          0.755788   \n",
       "\n",
       "  Training F1 Validation F1 Training ROC_AUC Validation ROC_AUC  \n",
       "0    0.736639      0.720072         0.627854           0.621808  \n",
       "1    0.978879      0.702098         0.956667           0.603428  \n",
       "2    0.763848      0.722934         0.714417           0.600164  \n",
       "3     0.73317      0.701699         0.625414           0.618171  \n",
       "4    0.728051      0.697753         0.625755           0.614282  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('cumulative_averages_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the Best Performing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Evaulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
