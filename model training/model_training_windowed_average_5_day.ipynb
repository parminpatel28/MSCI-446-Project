{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing Helper Functions\n",
    "from helper_functions import drop_extraneous_col, save_df\n",
    "# Recursive Feature Elimination with Cross-Validation\n",
    "from sklearn.feature_selection import RFECV\n",
    "# Time Series Split and GridSearchCV, where GridSearchCV is for hyperparameter tuning\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, cross_validate, RandomizedSearchCV\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Standard Scalar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, recall_score, precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "# Logistic Regression, Ridge Classifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "# Support Vector Machine (SVM)\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Sliding Window Average DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team0</th>\n",
       "      <th>team1</th>\n",
       "      <th>winner</th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>team0_encoded</th>\n",
       "      <th>team1_encoded</th>\n",
       "      <th>restDays_team0</th>\n",
       "      <th>restDays_team1</th>\n",
       "      <th>mp_rolling_team0</th>\n",
       "      <th>...</th>\n",
       "      <th>blk%_rolling_team1</th>\n",
       "      <th>tov%_rolling_team0</th>\n",
       "      <th>tov%_rolling_team1</th>\n",
       "      <th>ortg_rolling_team0</th>\n",
       "      <th>ortg_rolling_team1</th>\n",
       "      <th>drtg_rolling_team0</th>\n",
       "      <th>drtg_rolling_team1</th>\n",
       "      <th>ft/fga_rolling_team0</th>\n",
       "      <th>ft/fga_rolling_team1</th>\n",
       "      <th>team1_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOU</td>\n",
       "      <td>MEM</td>\n",
       "      <td>MEM</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-28</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.56</td>\n",
       "      <td>14.62</td>\n",
       "      <td>13.88</td>\n",
       "      <td>107.76</td>\n",
       "      <td>106.94</td>\n",
       "      <td>101.62</td>\n",
       "      <td>101.52</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLE</td>\n",
       "      <td>NOP</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-28</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.30</td>\n",
       "      <td>14.56</td>\n",
       "      <td>14.98</td>\n",
       "      <td>111.52</td>\n",
       "      <td>106.46</td>\n",
       "      <td>110.56</td>\n",
       "      <td>109.54</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHO</td>\n",
       "      <td>POR</td>\n",
       "      <td>POR</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-28</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.88</td>\n",
       "      <td>15.82</td>\n",
       "      <td>11.82</td>\n",
       "      <td>97.08</td>\n",
       "      <td>115.18</td>\n",
       "      <td>113.24</td>\n",
       "      <td>100.62</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHI</td>\n",
       "      <td>DAL</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-28</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.68</td>\n",
       "      <td>15.42</td>\n",
       "      <td>11.76</td>\n",
       "      <td>99.38</td>\n",
       "      <td>100.78</td>\n",
       "      <td>106.62</td>\n",
       "      <td>110.18</td>\n",
       "      <td>0.1702</td>\n",
       "      <td>0.2058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAS</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-29</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.66</td>\n",
       "      <td>12.78</td>\n",
       "      <td>12.66</td>\n",
       "      <td>104.44</td>\n",
       "      <td>111.82</td>\n",
       "      <td>101.60</td>\n",
       "      <td>113.66</td>\n",
       "      <td>0.2076</td>\n",
       "      <td>0.2278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7903</th>\n",
       "      <td>MIL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.90</td>\n",
       "      <td>9.52</td>\n",
       "      <td>7.76</td>\n",
       "      <td>123.72</td>\n",
       "      <td>133.44</td>\n",
       "      <td>125.26</td>\n",
       "      <td>111.12</td>\n",
       "      <td>0.2296</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7904</th>\n",
       "      <td>PHI</td>\n",
       "      <td>PHO</td>\n",
       "      <td>PHO</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>11.72</td>\n",
       "      <td>11.66</td>\n",
       "      <td>104.76</td>\n",
       "      <td>120.48</td>\n",
       "      <td>107.80</td>\n",
       "      <td>124.40</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7905</th>\n",
       "      <td>MIA</td>\n",
       "      <td>CLE</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.20</td>\n",
       "      <td>9.82</td>\n",
       "      <td>12.02</td>\n",
       "      <td>106.04</td>\n",
       "      <td>115.26</td>\n",
       "      <td>107.38</td>\n",
       "      <td>118.06</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>LAC</td>\n",
       "      <td>POR</td>\n",
       "      <td>LAC</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.22</td>\n",
       "      <td>12.54</td>\n",
       "      <td>14.36</td>\n",
       "      <td>117.64</td>\n",
       "      <td>109.26</td>\n",
       "      <td>125.26</td>\n",
       "      <td>120.46</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>MEM</td>\n",
       "      <td>GSW</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.40</td>\n",
       "      <td>14.20</td>\n",
       "      <td>10.70</td>\n",
       "      <td>106.36</td>\n",
       "      <td>116.68</td>\n",
       "      <td>115.98</td>\n",
       "      <td>119.44</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.1564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7908 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team0 team1 winner  season        date  team0_encoded  team1_encoded  \\\n",
       "0      HOU   MEM    MEM    2018  2017-10-28             29             28   \n",
       "1      CLE   NOP    NOP    2018  2017-10-28              6             30   \n",
       "2      PHO   POR    POR    2018  2017-10-28             24             17   \n",
       "3      PHI   DAL    PHI    2018  2017-10-28              5             27   \n",
       "4      SAS   IND    IND    2018  2017-10-29             26              7   \n",
       "...    ...   ...    ...     ...         ...            ...            ...   \n",
       "7903   MIL   BOS    BOS    2024  2024-03-20             10              2   \n",
       "7904   PHI   PHO    PHO    2024  2024-03-20              5             24   \n",
       "7905   MIA   CLE    MIA    2024  2024-03-20             11              6   \n",
       "7906   LAC   POR    LAC    2024  2024-03-20             22             17   \n",
       "7907   MEM   GSW    GSW    2024  2024-03-20             28             21   \n",
       "\n",
       "      restDays_team0  restDays_team1  mp_rolling_team0  ...  \\\n",
       "0                0.0             1.0             240.0  ...   \n",
       "1                2.0             1.0             240.0  ...   \n",
       "2                2.0             1.0             240.0  ...   \n",
       "3                2.0             1.0             240.0  ...   \n",
       "4                1.0             3.0             240.0  ...   \n",
       "...              ...             ...               ...  ...   \n",
       "7903             2.0             1.0             240.0  ...   \n",
       "7904             1.0             2.0             240.0  ...   \n",
       "7905             1.0             1.0             240.0  ...   \n",
       "7906             2.0             1.0             240.0  ...   \n",
       "7907             1.0             1.0             245.0  ...   \n",
       "\n",
       "      blk%_rolling_team1  tov%_rolling_team0  tov%_rolling_team1  \\\n",
       "0                   8.56               14.62               13.88   \n",
       "1                  10.30               14.56               14.98   \n",
       "2                  10.88               15.82               11.82   \n",
       "3                   5.68               15.42               11.76   \n",
       "4                   6.66               12.78               12.66   \n",
       "...                  ...                 ...                 ...   \n",
       "7903               12.90                9.52                7.76   \n",
       "7904                8.00               11.72               11.66   \n",
       "7905                7.20                9.82               12.02   \n",
       "7906                8.22               12.54               14.36   \n",
       "7907                8.40               14.20               10.70   \n",
       "\n",
       "      ortg_rolling_team0  ortg_rolling_team1  drtg_rolling_team0  \\\n",
       "0                 107.76              106.94              101.62   \n",
       "1                 111.52              106.46              110.56   \n",
       "2                  97.08              115.18              113.24   \n",
       "3                  99.38              100.78              106.62   \n",
       "4                 104.44              111.82              101.60   \n",
       "...                  ...                 ...                 ...   \n",
       "7903              123.72              133.44              125.26   \n",
       "7904              104.76              120.48              107.80   \n",
       "7905              106.04              115.26              107.38   \n",
       "7906              117.64              109.26              125.26   \n",
       "7907              106.36              116.68              115.98   \n",
       "\n",
       "      drtg_rolling_team1  ft/fga_rolling_team0  ft/fga_rolling_team1  \\\n",
       "0                 101.52                0.2350                0.3258   \n",
       "1                 109.54                0.2222                0.2284   \n",
       "2                 100.62                0.2390                0.2568   \n",
       "3                 110.18                0.1702                0.2058   \n",
       "4                 113.66                0.2076                0.2278   \n",
       "...                  ...                   ...                   ...   \n",
       "7903              111.12                0.2296                0.1402   \n",
       "7904              124.40                0.1580                0.1348   \n",
       "7905              118.06                0.1430                0.1680   \n",
       "7906              120.46                0.2178                0.1768   \n",
       "7907              119.44                0.2044                0.1564   \n",
       "\n",
       "      team1_winner  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                0  \n",
       "4                1  \n",
       "...            ...  \n",
       "7903             1  \n",
       "7904             1  \n",
       "7905             0  \n",
       "7906             0  \n",
       "7907             1  \n",
       "\n",
       "[7908 rows x 76 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df  = pd.read_csv('/Users/siddmittal/Documents/School/3B/MSCI-446-Project/csvs/rolling_average_5_day.csv')\n",
    "drop_extraneous_col(training_df)\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataframe into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "undesired_columns = ['team0', 'team1', 'winner', 'season', 'date', 'team1_winner']\n",
    "# We decided to train from the 2018 season to the 2023 season\n",
    "training_seasons = [2018,2019,2020,2021,2022,2023]\n",
    "# Splitting the dataframe into train and test\n",
    "X_train = training_df[training_df['season'].isin(training_seasons)].drop(undesired_columns, axis=1)\n",
    "X_test = training_df[training_df['season'] == 2024].drop(undesired_columns, axis=1)\n",
    "y_train = training_df[training_df['season'].isin(training_seasons)]['team1_winner']\n",
    "y_test = training_df[training_df['season'] == 2024]['team1_winner']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in X_train: 6967\n",
      "Observations in y_train: 6967\n",
      "Observations in X_test: 941\n",
      "Observations in y_test: 941\n"
     ]
    }
   ],
   "source": [
    "# Double checking the shapes of the training and testing dataframes\n",
    "\n",
    "print(f'Observations in X_train: {X_train.shape[0]}')\n",
    "print(f'Observations in y_train: {y_train.shape[0]}')\n",
    "\n",
    "print(f'Observations in X_test: {X_test.shape[0]}')\n",
    "print(f'Observations in y_test: {y_test.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scalar = StandardScaler()\n",
    "X_train = std_scalar.fit_transform(X_train)\n",
    "X_test = std_scalar.fit_transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Type of Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the type of cross validation\n",
    "tscv = TimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Results DataFrame to Store Training and Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Model', 'Training Accuracy', 'Validation Accuracy',\n",
    "                             'Training Precision', 'Validation Precision',\n",
    "                             'Training Recall ', 'Validation Recall',\n",
    "                             'Training F1', 'Validation F1',\n",
    "                             'Training ROC_AUC', 'Validation ROC_AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the Logistic Regresion Model\n",
    "model_lr = LogisticRegression(solver='saga', max_iter=5000, random_state=42)\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_lr = RFECV(estimator = model_lr, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_lr.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_lr.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(estimator=model_lr, param_grid=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "grid_search_lr.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_lr = grid_search_lr.cv_results_\n",
    "\n",
    "new_row_data = ['Logistic Regression']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_lr[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_lr[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_lr[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "num_features_lr = model_rfecv_lr.n_features_\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the RandomForestClassifier Model\n",
    "model_rfc = RandomForestClassifier(random_state=42)\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_rfc = RFECV(estimator = model_rfc, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_rfc.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_rfc.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],       # Number of trees in the forest.\n",
    "    'max_depth': [None, 10, 20, 30],        # Maximum depth of the tree.\n",
    "    'min_samples_split': [2, 5, 10],        # Minimum number of samples required to split an internal node.\n",
    "    'min_samples_leaf': [1, 2, 4], \n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "random_search_rfc = RandomizedSearchCV(estimator=model_rfc, n_iter=100, param_distributions=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "random_search_rfc.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_rfc = random_search_rfc.cv_results_\n",
    "\n",
    "new_row_data = ['Random Forest Classifier']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_rfc[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_rfc[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_rfc[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "num_features_rfc = model_rfecv_rfc.n_features_\n",
    "best_params_rfc = random_search_rfc.best_params_\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the XGB Classifier Model\n",
    "model_xgb = XGBClassifier(objective='binary:logistic')\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_xgb = RFECV(estimator = model_xgb, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_xgb.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_xgb.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(estimator=model_xgb, n_iter=100, param_distributions=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "random_search_xgb.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_xgb = random_search_xgb.cv_results_\n",
    "\n",
    "new_row_data = ['XGB Classifier']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_xgb[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_xgb[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_xgb[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "num_features_xgb = model_rfecv_xgb.n_features_\n",
    "best_params_xgb = random_search_xgb.best_params_\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the Support Vector Machine Model\n",
    "model_svm = LinearSVC(max_iter=5000, random_state=42, dual='auto')\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_svm = RFECV(estimator = model_svm, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_svm.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_svm.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'],  # Penalty\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(estimator=model_svm, param_grid=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "grid_search_svm.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_svm = grid_search_svm.cv_results_\n",
    "\n",
    "new_row_data = ['Linear SVC']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_svm[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_svm[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_svm[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "num_features_svm = model_rfecv_svm.n_features_\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Validation Precision</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Validation Recall</th>\n",
       "      <th>Training F1</th>\n",
       "      <th>Validation F1</th>\n",
       "      <th>Training ROC_AUC</th>\n",
       "      <th>Validation ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.638975</td>\n",
       "      <td>0.613781</td>\n",
       "      <td>0.658646</td>\n",
       "      <td>0.635029</td>\n",
       "      <td>0.927034</td>\n",
       "      <td>0.918632</td>\n",
       "      <td>0.734622</td>\n",
       "      <td>0.71832</td>\n",
       "      <td>0.615209</td>\n",
       "      <td>0.591555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.992214</td>\n",
       "      <td>0.597933</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.613177</td>\n",
       "      <td>0.992141</td>\n",
       "      <td>0.827351</td>\n",
       "      <td>0.937847</td>\n",
       "      <td>0.698188</td>\n",
       "      <td>0.990752</td>\n",
       "      <td>0.568822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>0.731828</td>\n",
       "      <td>0.600172</td>\n",
       "      <td>0.970976</td>\n",
       "      <td>0.621755</td>\n",
       "      <td>0.963524</td>\n",
       "      <td>0.934788</td>\n",
       "      <td>0.836611</td>\n",
       "      <td>0.720567</td>\n",
       "      <td>0.988134</td>\n",
       "      <td>0.573162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.640713</td>\n",
       "      <td>0.612231</td>\n",
       "      <td>0.655526</td>\n",
       "      <td>0.636818</td>\n",
       "      <td>0.796979</td>\n",
       "      <td>0.74859</td>\n",
       "      <td>0.71934</td>\n",
       "      <td>0.685538</td>\n",
       "      <td>0.611674</td>\n",
       "      <td>0.594223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Training Accuracy Validation Accuracy  \\\n",
       "0       Logistic Regression          0.638975            0.613781   \n",
       "1  Random Forest Classifier          0.992214            0.597933   \n",
       "2            XGB Classifier          0.731828            0.600172   \n",
       "3                Linear SVC          0.640713            0.612231   \n",
       "\n",
       "  Training Precision Validation Precision Training Recall  Validation Recall  \\\n",
       "0           0.658646             0.635029         0.927034          0.918632   \n",
       "1                1.0             0.613177         0.992141          0.827351   \n",
       "2           0.970976             0.621755         0.963524          0.934788   \n",
       "3           0.655526             0.636818         0.796979           0.74859   \n",
       "\n",
       "  Training F1 Validation F1 Training ROC_AUC Validation ROC_AUC  \n",
       "0    0.734622       0.71832         0.615209           0.591555  \n",
       "1    0.937847      0.698188         0.990752           0.568822  \n",
       "2    0.836611      0.720567         0.988134           0.573162  \n",
       "3     0.71934      0.685538         0.611674           0.594223  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'penalty': 'l1'}\n",
      "{'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 30}\n",
      "{'subsample': 0.7, 'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.9}\n",
      "{'C': 0.1, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params_lr)\n",
    "print(best_params_rfc)\n",
    "print(best_params_xgb)\n",
    "print(best_params_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "67\n",
      "54\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "print(num_features_lr)\n",
    "print(num_features_rfc)\n",
    "print(num_features_xgb)\n",
    "print(num_features_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(results_df, \"rolling_average_5_day_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
