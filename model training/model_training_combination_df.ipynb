{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing Helper Functions\n",
    "from helper_functions import drop_extraneous_col, save_df\n",
    "# Recursive Feature Elimination with Cross-Validation\n",
    "from sklearn.feature_selection import RFECV\n",
    "# Time Series Split and GridSearchCV, where GridSearchCV is for hyperparameter tuning\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, cross_validate, RandomizedSearchCV\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Standard Scalar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, recall_score, precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "# Logistic Regression, Ridge Classifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "# Support Vector Machine (SVM)\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Cumulative Averages DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_df = pd.read_csv('/Users/siddmittal/Documents/School/3B/MSCI-446-Project/csvs/cumulative_averages.csv')\n",
    "prev_game_df = pd.read_csv('/Users/siddmittal/Documents/School/3B/MSCI-446-Project/csvs/prev_game_df.csv')\n",
    "\n",
    "drop_extraneous_col(cumulative_df)\n",
    "drop_extraneous_col(prev_game_df)\n",
    "\n",
    "training_df = pd.concat([cumulative_df, prev_game_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df.loc[:,~training_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team0</th>\n",
       "      <th>team1</th>\n",
       "      <th>winner</th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>team0_encoded</th>\n",
       "      <th>team1_encoded</th>\n",
       "      <th>restDays_team0</th>\n",
       "      <th>restDays_team1</th>\n",
       "      <th>mp_cumulative_team0</th>\n",
       "      <th>...</th>\n",
       "      <th>orb%_prev_game_team0</th>\n",
       "      <th>drb%_prev_game_team0</th>\n",
       "      <th>trb%_prev_game_team0</th>\n",
       "      <th>ast%_prev_game_team0</th>\n",
       "      <th>stl%_prev_game_team0</th>\n",
       "      <th>blk%_prev_game_team0</th>\n",
       "      <th>tov%_prev_game_team0</th>\n",
       "      <th>ortg_prev_game_team0</th>\n",
       "      <th>drtg_prev_game_team0</th>\n",
       "      <th>ft/fga_prev_game_team0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLE</td>\n",
       "      <td>MIL</td>\n",
       "      <td>CLE</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>52.1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>15.3</td>\n",
       "      <td>102.7</td>\n",
       "      <td>99.7</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAL</td>\n",
       "      <td>PHO</td>\n",
       "      <td>LAL</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.2</td>\n",
       "      <td>70.2</td>\n",
       "      <td>46.8</td>\n",
       "      <td>56.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>15.8</td>\n",
       "      <td>86.9</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSW</td>\n",
       "      <td>NOP</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.4</td>\n",
       "      <td>77.8</td>\n",
       "      <td>48.8</td>\n",
       "      <td>79.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>118.6</td>\n",
       "      <td>119.6</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORL</td>\n",
       "      <td>BRK</td>\n",
       "      <td>BRK</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>51.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>110.3</td>\n",
       "      <td>103.6</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOS</td>\n",
       "      <td>PHI</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>84.2</td>\n",
       "      <td>48.9</td>\n",
       "      <td>59.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>102.2</td>\n",
       "      <td>110.4</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8350</th>\n",
       "      <td>MIL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>241.119403</td>\n",
       "      <td>...</td>\n",
       "      <td>23.8</td>\n",
       "      <td>78.1</td>\n",
       "      <td>47.3</td>\n",
       "      <td>68.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>143.4</td>\n",
       "      <td>132.2</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8351</th>\n",
       "      <td>PHI</td>\n",
       "      <td>PHO</td>\n",
       "      <td>PHO</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>240.735294</td>\n",
       "      <td>...</td>\n",
       "      <td>15.6</td>\n",
       "      <td>78.0</td>\n",
       "      <td>48.4</td>\n",
       "      <td>62.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>102.8</td>\n",
       "      <td>95.4</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8352</th>\n",
       "      <td>MIA</td>\n",
       "      <td>CLE</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.384615</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>84.4</td>\n",
       "      <td>51.6</td>\n",
       "      <td>65.7</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>95.4</td>\n",
       "      <td>102.8</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8353</th>\n",
       "      <td>LAC</td>\n",
       "      <td>POR</td>\n",
       "      <td>LAC</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.373134</td>\n",
       "      <td>...</td>\n",
       "      <td>22.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>47.1</td>\n",
       "      <td>60.7</td>\n",
       "      <td>11.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>102.8</td>\n",
       "      <td>121.6</td>\n",
       "      <td>0.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8354</th>\n",
       "      <td>MEM</td>\n",
       "      <td>GSW</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>241.449275</td>\n",
       "      <td>...</td>\n",
       "      <td>25.4</td>\n",
       "      <td>69.4</td>\n",
       "      <td>45.4</td>\n",
       "      <td>59.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>11.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>104.6</td>\n",
       "      <td>114.1</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8355 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team0 team1 winner  season        date  team0_encoded  team1_encoded  \\\n",
       "0      CLE   MIL    CLE    2018  2017-10-20              6             10   \n",
       "1      LAL   PHO    LAL    2018  2017-10-20             25             24   \n",
       "2      GSW   NOP    GSW    2018  2017-10-20             21             30   \n",
       "3      ORL   BRK    BRK    2018  2017-10-20             15              4   \n",
       "4      BOS   PHI    BOS    2018  2017-10-20              2              5   \n",
       "...    ...   ...    ...     ...         ...            ...            ...   \n",
       "8350   MIL   BOS    BOS    2024  2024-03-20             10              2   \n",
       "8351   PHI   PHO    PHO    2024  2024-03-20              5             24   \n",
       "8352   MIA   CLE    MIA    2024  2024-03-20             11              6   \n",
       "8353   LAC   POR    LAC    2024  2024-03-20             22             17   \n",
       "8354   MEM   GSW    GSW    2024  2024-03-20             28             21   \n",
       "\n",
       "      restDays_team0  restDays_team1  mp_cumulative_team0  ...  \\\n",
       "0                2.0             1.0           240.000000  ...   \n",
       "1                0.0             1.0           240.000000  ...   \n",
       "2                2.0             1.0           240.000000  ...   \n",
       "3                1.0             1.0           240.000000  ...   \n",
       "4                1.0             1.0           240.000000  ...   \n",
       "...              ...             ...                  ...  ...   \n",
       "8350             2.0             1.0           241.119403  ...   \n",
       "8351             1.0             2.0           240.735294  ...   \n",
       "8352             1.0             1.0           240.384615  ...   \n",
       "8353             2.0             1.0           240.373134  ...   \n",
       "8354             1.0             1.0           241.449275  ...   \n",
       "\n",
       "      orb%_prev_game_team0  drb%_prev_game_team0  trb%_prev_game_team0  \\\n",
       "0                     19.6                  82.0                  52.1   \n",
       "1                     22.2                  70.2                  46.8   \n",
       "2                     15.4                  77.8                  48.8   \n",
       "3                     25.0                  78.0                  53.2   \n",
       "4                     22.0                  84.2                  48.9   \n",
       "...                    ...                   ...                   ...   \n",
       "8350                  23.8                  78.1                  47.3   \n",
       "8351                  15.6                  78.0                  48.4   \n",
       "8352                  22.0                  84.4                  51.6   \n",
       "8353                  22.2                  75.0                  47.1   \n",
       "8354                  25.4                  69.4                  45.4   \n",
       "\n",
       "      ast%_prev_game_team0  stl%_prev_game_team0  blk%_prev_game_team0  \\\n",
       "0                     50.0                   3.0                   7.1   \n",
       "1                     56.8                   7.6                   9.5   \n",
       "2                     79.1                   4.9                  16.1   \n",
       "3                     51.2                   7.6                  12.7   \n",
       "4                     59.0                  12.3                   3.6   \n",
       "...                    ...                   ...                   ...   \n",
       "8350                  68.6                  11.3                   3.7   \n",
       "8351                  62.2                   7.3                  21.4   \n",
       "8352                  65.7                   8.4                   6.1   \n",
       "8353                  60.7                  11.1                  10.0   \n",
       "8354                  59.5                  12.3                  11.9   \n",
       "\n",
       "      tov%_prev_game_team0  ortg_prev_game_team0  drtg_prev_game_team0  \\\n",
       "0                     15.3                 102.7                  99.7   \n",
       "1                     15.8                  86.9                 102.0   \n",
       "2                     16.0                 118.6                 119.6   \n",
       "3                     12.0                 110.3                 103.6   \n",
       "4                     10.7                 102.2                 110.4   \n",
       "...                    ...                   ...                   ...   \n",
       "8350                   9.1                 143.4                 132.2   \n",
       "8351                  11.7                 102.8                  95.4   \n",
       "8352                  13.6                  95.4                 102.8   \n",
       "8353                  14.7                 102.8                 121.6   \n",
       "8354                   9.7                 104.6                 114.1   \n",
       "\n",
       "      ft/fga_prev_game_team0  \n",
       "0                      0.253  \n",
       "1                      0.154  \n",
       "2                      0.238  \n",
       "3                      0.244  \n",
       "4                      0.121  \n",
       "...                      ...  \n",
       "8350                   0.149  \n",
       "8351                   0.129  \n",
       "8352                   0.101  \n",
       "8353                   0.351  \n",
       "8354                   0.245  \n",
       "\n",
       "[8355 rows x 142 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataframe into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "undesired_columns = ['team0', 'team1', 'winner', 'season', 'date', 'team1_winner']\n",
    "# We decided to train from the 2018 season to the 2023 season\n",
    "training_seasons = [2018,2019,2020,2021,2022,2023]\n",
    "# Splitting the dataframe into train and test\n",
    "X_train = training_df[training_df['season'].isin(training_seasons)].drop(undesired_columns, axis=1)\n",
    "X_test = training_df[training_df['season'] == 2024].drop(undesired_columns, axis=1)\n",
    "y_train = training_df[training_df['season'].isin(training_seasons)]['team1_winner']\n",
    "y_test = training_df[training_df['season'] == 2024]['team1_winner']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in X_train: 7348\n",
      "Observations in y_train: 7348\n",
      "Observations in X_test: 1007\n",
      "Observations in y_test: 1007\n"
     ]
    }
   ],
   "source": [
    "# Double checking the shapes of the training and testing dataframes\n",
    "\n",
    "print(f'Observations in X_train: {X_train.shape[0]}')\n",
    "print(f'Observations in y_train: {y_train.shape[0]}')\n",
    "\n",
    "print(f'Observations in X_test: {X_test.shape[0]}')\n",
    "print(f'Observations in y_test: {y_test.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scalar = StandardScaler()\n",
    "X_train = std_scalar.fit_transform(X_train)\n",
    "X_test = std_scalar.fit_transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Type of Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the type of cross validation\n",
    "tscv = TimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Results DataFrame to Store Training and Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Model', 'Training Accuracy', 'Validation Accuracy',\n",
    "                             'Training Precision', 'Validation Precision',\n",
    "                             'Training Recall ', 'Validation Recall',\n",
    "                             'Training F1', 'Validation F1',\n",
    "                             'Training ROC_AUC', 'Validation ROC_AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the Logistic Regresion Model\n",
    "model_lr = LogisticRegression(solver='saga', max_iter=5000, random_state=42)\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_lr = RFECV(estimator = model_lr, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_lr.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_lr.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(estimator=model_lr, param_grid=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "grid_search_lr.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_lr = grid_search_lr.cv_results_\n",
    "\n",
    "new_row_data = ['Logistic Regression']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_lr[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_lr[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_lr[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "num_features_lr = model_rfecv_lr.n_features_\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the RandomForestClassifier Model\n",
    "model_rfc = RandomForestClassifier(random_state=42)\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_rfc = RFECV(estimator = model_rfc, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_rfc.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_rfc.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],       # Number of trees in the forest.\n",
    "    'max_depth': [None, 10, 20, 30],        # Maximum depth of the tree.\n",
    "    'min_samples_split': [2, 5, 10],        # Minimum number of samples required to split an internal node.\n",
    "    'min_samples_leaf': [1, 2, 4], \n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "random_search_rfc = RandomizedSearchCV(estimator=model_rfc, n_iter=100, param_distributions=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "random_search_rfc.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_rfc = random_search_rfc.cv_results_\n",
    "\n",
    "new_row_data = ['Random Forest Classifier']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_rfc[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_rfc[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_rfc[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "num_features_rfc = model_rfecv_rfc.n_features_\n",
    "best_params_rfc = random_search_rfc.best_params_\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the XGB Classifier Model\n",
    "model_xgb = XGBClassifier(objective='binary:logistic')\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_xgb = RFECV(estimator = model_xgb, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_xgb.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_xgb.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(estimator=model_xgb, n_iter=100, param_distributions=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "random_search_xgb.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_xgb = random_search_xgb.cv_results_\n",
    "\n",
    "new_row_data = ['XGB Classifier']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_xgb[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_xgb[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_xgb[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "num_features_xgb = model_rfecv_xgb.n_features_\n",
    "best_params_xgb = random_search_xgb.best_params_\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/siddmittal/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the Support Vector Machine Model\n",
    "model_svm = LinearSVC(max_iter=5000, random_state=42, dual='auto')\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_svm = RFECV(estimator = model_svm, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_svm.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_svm.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'],  # Penalty\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(estimator=model_svm, param_grid=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "grid_search_svm.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_svm = grid_search_svm.cv_results_\n",
    "\n",
    "new_row_data = ['Linear SVC']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_svm[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_svm[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_svm[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "num_features_svm = model_rfecv_svm.n_features_\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Validation Precision</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Validation Recall</th>\n",
       "      <th>Training F1</th>\n",
       "      <th>Validation F1</th>\n",
       "      <th>Training ROC_AUC</th>\n",
       "      <th>Validation ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.653676</td>\n",
       "      <td>0.633007</td>\n",
       "      <td>0.671728</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>0.901078</td>\n",
       "      <td>0.89119</td>\n",
       "      <td>0.736857</td>\n",
       "      <td>0.719659</td>\n",
       "      <td>0.628283</td>\n",
       "      <td>0.616199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.921446</td>\n",
       "      <td>0.625817</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.641243</td>\n",
       "      <td>0.982894</td>\n",
       "      <td>0.79238</td>\n",
       "      <td>0.949626</td>\n",
       "      <td>0.705055</td>\n",
       "      <td>0.933047</td>\n",
       "      <td>0.603987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>0.843363</td>\n",
       "      <td>0.621242</td>\n",
       "      <td>0.99139</td>\n",
       "      <td>0.638448</td>\n",
       "      <td>0.933242</td>\n",
       "      <td>0.906406</td>\n",
       "      <td>0.790881</td>\n",
       "      <td>0.72448</td>\n",
       "      <td>0.929741</td>\n",
       "      <td>0.596454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.654781</td>\n",
       "      <td>0.628922</td>\n",
       "      <td>0.674252</td>\n",
       "      <td>0.656741</td>\n",
       "      <td>0.806736</td>\n",
       "      <td>0.740571</td>\n",
       "      <td>0.729382</td>\n",
       "      <td>0.691225</td>\n",
       "      <td>0.637309</td>\n",
       "      <td>0.613532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Training Accuracy Validation Accuracy  \\\n",
       "0       Logistic Regression          0.653676            0.633007   \n",
       "1  Random Forest Classifier          0.921446            0.625817   \n",
       "2            XGB Classifier          0.843363            0.621242   \n",
       "3                Linear SVC          0.654781            0.628922   \n",
       "\n",
       "  Training Precision Validation Precision Training Recall  Validation Recall  \\\n",
       "0           0.671728               0.6576         0.901078           0.89119   \n",
       "1           0.999511             0.641243         0.982894           0.79238   \n",
       "2            0.99139             0.638448         0.933242          0.906406   \n",
       "3           0.674252             0.656741         0.806736          0.740571   \n",
       "\n",
       "  Training F1 Validation F1 Training ROC_AUC Validation ROC_AUC  \n",
       "0    0.736857      0.719659         0.628283           0.616199  \n",
       "1    0.949626      0.705055         0.933047           0.603987  \n",
       "2    0.790881       0.72448         0.929741           0.596454  \n",
       "3    0.729382      0.691225         0.637309           0.613532  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'penalty': 'l1'}\n",
      "{'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 10}\n",
      "{'subsample': 0.7, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.5}\n",
      "{'C': 0.1, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print(best_params_lr)\n",
    "print(best_params_rfc)\n",
    "print(best_params_xgb)\n",
    "print(best_params_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "49\n",
      "116\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "print(num_features_lr)\n",
    "print(num_features_rfc)\n",
    "print(num_features_xgb)\n",
    "print(num_features_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(results_df, \"cominbation_df_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
