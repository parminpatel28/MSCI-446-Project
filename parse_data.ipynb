{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Frameworks + Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointer Logic\n",
    "\n",
    "- Create pointer variables to save .html files to a particular directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE_DIR = \"scores\"\n",
    "box_scores = os.listdir(SCORE_DIR)\n",
    "box_scores = [os.path.join(SCORE_DIR, f) for f in box_scores if f.endswith(\".html\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse HTML Function\n",
    "\n",
    "- Takes in a particular HTML file for a specific game, and removes excess table data that is not required in the df (s.decompose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(box_score):\n",
    "    with open(box_score) as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    [s.decompose() for s in soup.select(\"tr.over_header\")]\n",
    "    [s.decompose() for s in soup.select(\"tr.thead\")]\n",
    "\n",
    "    return soup\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Line Score\n",
    "\n",
    "- Takes in a BeautifulSoup object to parse the total points/teams playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_line_score(soup):\n",
    "    line_score = pd.read_html(str(soup), attrs={\"id\": \"line_score\"})[0]\n",
    "    cols = list(line_score.columns)\n",
    "    cols[0] = \"team\"\n",
    "    cols[-1] = \"total\"\n",
    "    line_score.columns = cols\n",
    "\n",
    "    line_score = line_score[[\"team\", \"total\"]]\n",
    "    return line_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Stats\n",
    "\n",
    "- Reads in the boxscore HTML table and converts it to a dataframe using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stats(soup, team, stat) -> pd.DataFrame:\n",
    "    df = pd.read_html(str(soup), attrs={\"id\": f\"box-{team}-game-{stat}\"}, index_col=0)[0]\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Season Info\n",
    "\n",
    "- Returns the particular season info of the game we are currently parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_season_info(soup) -> pd.DataFrame:\n",
    "    nav = soup.select(\"#bottom_nav_container\")[0]\n",
    "    hrefs = [a[\"href\"] for a in nav.find_all(\"a\")]\n",
    "    season = os.path.basename(hrefs[1]).split(\"_\")[0]\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cols = None\n",
    "games = []\n",
    "\n",
    "for box_score in box_scores[:30]:\n",
    "    soup = parse_html(box_score)\n",
    "    line_score = read_line_score(soup)\n",
    "\n",
    "    teams = list(line_score[\"team\"])\n",
    "    summaries = []\n",
    "    team_mapping = {}\n",
    "\n",
    "    for i, team in enumerate(teams):\n",
    "        team_mapping[f\"team{i}\"] = team\n",
    "        basic = read_stats(soup, team, \"basic\")\n",
    "        advanced = read_stats(soup, team, \"advanced\")\n",
    "\n",
    "        # only take the final row in the DataFrame and concatenate basic and advanced stats \n",
    "        totals = pd.concat([basic.iloc[-1,:], advanced.iloc[-1,:]])\n",
    "\n",
    "        totals.index = totals.index.str.lower() + f\"_team{i}\"\n",
    "\n",
    "        if base_cols is None:\n",
    "            base_cols = list(totals.index.drop_duplicates(keep=\"first\"))\n",
    "            base_cols = [b for b in base_cols if \"bpm\" not in b]\n",
    "            \n",
    "        totals[f\"team{i}\"] = team\n",
    "        summaries.append(totals)\n",
    "\n",
    "    game = pd.concat(summaries, axis=0)\n",
    "    game[\"winner\"] = team_mapping[\"team0\"] if game[\"pts_team0\"] > game[\"pts_team1\"] else team_mapping[\"team1\"]\n",
    "    game = game.to_frame().T\n",
    "\n",
    "    game[\"season\"] = read_season_info(soup)\n",
    "    game[\"date\"] = os.path.basename(box_score)[:8]\n",
    "    game[\"date\"] = pd.to_datetime(game[\"date\"], format=\"%Y%m%d\")\n",
    "    games.append(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m games \u001b[38;5;241m=\u001b[39m [df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m games]\n\u001b[0;32m----> 2\u001b[0m games_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/pandas/core/reshape/concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m     objs,\n\u001b[1;32m    370\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    379\u001b[0m )\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/pandas/core/reshape/concat.py:612\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> 612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m    616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    618\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/pandas/core/indexes/base.py:3904\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3907\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "games = [df.reset_index(drop=True) for df in games]\n",
    "games_df = pd.concat(games, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = games_df.sort_values(by=\"date\")\n",
    "games_df = games_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Data\n",
    "\n",
    "- label encoding --> went with this one for now, but am not sure if this is good since it implies some type of ordering which is not true\n",
    "- one-hot encoding --> this one will add 30 columns to the df, is this what we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_encoding = { \n",
    "    # ATLANTIC\n",
    "    \"TOR\": 1,\n",
    "    \"BOS\": 2,\n",
    "    \"NYK\": 3, \n",
    "    \"BRK\": 4,\n",
    "    \"PHI\": 5,\n",
    "\n",
    "    # CENTRAL\n",
    "    \"CLE\": 6,\n",
    "    \"IND\": 7,\n",
    "    \"DET\": 8,\n",
    "    \"CHI\": 9,\n",
    "    \"MIL\": 10,\n",
    "\n",
    "    # SOUTHEAST\n",
    "    \"MIA\": 11,\n",
    "    \"ATL\": 12,\n",
    "    \"CHO\": 13,\n",
    "    \"WAS\": 14,\n",
    "    \"ORL\": 15,\n",
    "\n",
    "    # NORTHWEST\n",
    "    \"OKC\": 16,\n",
    "    \"POR\": 17,\n",
    "    \"UTA\": 18,\n",
    "    \"DEN\": 19,\n",
    "    \"MIN\": 20,\n",
    "\n",
    "    # PACIFIC\n",
    "    \"GSW\": 21, \n",
    "    \"LAC\": 22,\n",
    "    \"SAC\": 23,\n",
    "    \"PHO\": 24,\n",
    "    \"LAL\": 25,\n",
    "\n",
    "    # SOUTH WEST\n",
    "    \"SAS\": 26,\n",
    "    \"DAL\": 27,\n",
    "    \"MEM\": 28,\n",
    "    \"HOU\": 29,\n",
    "    \"NOP\": 30\n",
    "}\n",
    "\n",
    "# update those values\n",
    "encoded_games_df = games_df\n",
    "\n",
    "encoded_games_df.replace(team_encoding, inplace=True)\n",
    "\n",
    "encoded_games_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Average Logic    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
