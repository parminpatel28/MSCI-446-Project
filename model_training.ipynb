{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing Helper Functions\n",
    "from helper_functions import drop_extraneous_col\n",
    "# Recursive Feature Elimination with Cross-Validation\n",
    "from sklearn.feature_selection import RFECV\n",
    "# Time Series Split and GridSearchCV, where GridSearchCV is for hyperparameter tuning\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, cross_validate, RandomizedSearchCV\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Standard Scalar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, recall_score, precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "# Logistic Regression, Ridge Classifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "# Support Vector Machine (SVM)\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Previous Game DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team0</th>\n",
       "      <th>team1</th>\n",
       "      <th>winner</th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>team0_encoded</th>\n",
       "      <th>team1_encoded</th>\n",
       "      <th>mp_cumulative_team0</th>\n",
       "      <th>mp_cumulative_team1</th>\n",
       "      <th>fg_cumulative_team0</th>\n",
       "      <th>...</th>\n",
       "      <th>stl%_cumulative_team1</th>\n",
       "      <th>blk%_cumulative_team0</th>\n",
       "      <th>blk%_cumulative_team1</th>\n",
       "      <th>tov%_cumulative_team0</th>\n",
       "      <th>tov%_cumulative_team1</th>\n",
       "      <th>ortg_cumulative_team0</th>\n",
       "      <th>ortg_cumulative_team1</th>\n",
       "      <th>drtg_cumulative_team0</th>\n",
       "      <th>drtg_cumulative_team1</th>\n",
       "      <th>team1_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAC</td>\n",
       "      <td>DAL</td>\n",
       "      <td>SAC</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>103.900000</td>\n",
       "      <td>112.600000</td>\n",
       "      <td>109.100000</td>\n",
       "      <td>118.700000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POR</td>\n",
       "      <td>IND</td>\n",
       "      <td>POR</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>125.600000</td>\n",
       "      <td>123.600000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>115.700000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORL</td>\n",
       "      <td>BRK</td>\n",
       "      <td>BRK</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>110.300000</td>\n",
       "      <td>115.700000</td>\n",
       "      <td>103.600000</td>\n",
       "      <td>123.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS</td>\n",
       "      <td>PHI</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.950000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>100.950000</td>\n",
       "      <td>110.300000</td>\n",
       "      <td>106.550000</td>\n",
       "      <td>115.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DET</td>\n",
       "      <td>WAS</td>\n",
       "      <td>WAS</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>103.600000</td>\n",
       "      <td>115.100000</td>\n",
       "      <td>91.400000</td>\n",
       "      <td>110.300000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8350</th>\n",
       "      <td>PHI</td>\n",
       "      <td>PHO</td>\n",
       "      <td>PHO</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>240.735294</td>\n",
       "      <td>241.470588</td>\n",
       "      <td>41.455882</td>\n",
       "      <td>...</td>\n",
       "      <td>7.380882</td>\n",
       "      <td>10.872059</td>\n",
       "      <td>10.926471</td>\n",
       "      <td>10.083824</td>\n",
       "      <td>12.583824</td>\n",
       "      <td>117.983824</td>\n",
       "      <td>118.973529</td>\n",
       "      <td>115.505882</td>\n",
       "      <td>116.622059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8351</th>\n",
       "      <td>UTA</td>\n",
       "      <td>OKC</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>241.838235</td>\n",
       "      <td>241.515152</td>\n",
       "      <td>42.588235</td>\n",
       "      <td>...</td>\n",
       "      <td>8.290909</td>\n",
       "      <td>10.625000</td>\n",
       "      <td>12.915152</td>\n",
       "      <td>12.877941</td>\n",
       "      <td>10.440909</td>\n",
       "      <td>117.452941</td>\n",
       "      <td>121.086364</td>\n",
       "      <td>120.983824</td>\n",
       "      <td>113.606061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8352</th>\n",
       "      <td>IND</td>\n",
       "      <td>DET</td>\n",
       "      <td>IND</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>240.367647</td>\n",
       "      <td>241.102941</td>\n",
       "      <td>46.382353</td>\n",
       "      <td>...</td>\n",
       "      <td>6.185294</td>\n",
       "      <td>9.545588</td>\n",
       "      <td>8.539706</td>\n",
       "      <td>10.958824</td>\n",
       "      <td>13.114706</td>\n",
       "      <td>120.725000</td>\n",
       "      <td>111.780882</td>\n",
       "      <td>119.098529</td>\n",
       "      <td>120.054412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8353</th>\n",
       "      <td>MIL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>241.119403</td>\n",
       "      <td>241.838235</td>\n",
       "      <td>43.268657</td>\n",
       "      <td>...</td>\n",
       "      <td>6.738235</td>\n",
       "      <td>8.637313</td>\n",
       "      <td>11.938235</td>\n",
       "      <td>10.864179</td>\n",
       "      <td>10.339706</td>\n",
       "      <td>119.949254</td>\n",
       "      <td>124.129412</td>\n",
       "      <td>116.650746</td>\n",
       "      <td>112.086765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8354</th>\n",
       "      <td>LAC</td>\n",
       "      <td>POR</td>\n",
       "      <td>LAC</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>240.373134</td>\n",
       "      <td>242.985075</td>\n",
       "      <td>42.507463</td>\n",
       "      <td>...</td>\n",
       "      <td>7.995522</td>\n",
       "      <td>9.485075</td>\n",
       "      <td>8.408955</td>\n",
       "      <td>11.274627</td>\n",
       "      <td>12.708955</td>\n",
       "      <td>120.468657</td>\n",
       "      <td>110.244776</td>\n",
       "      <td>116.623881</td>\n",
       "      <td>118.516418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8355 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team0 team1 winner  season        date  team0_encoded  team1_encoded  \\\n",
       "0      SAC   DAL    SAC    2018  2017-10-20             23             27   \n",
       "1      POR   IND    POR    2018  2017-10-20             17              7   \n",
       "2      ORL   BRK    BRK    2018  2017-10-20             15              4   \n",
       "3      BOS   PHI    BOS    2018  2017-10-20              2              5   \n",
       "4      DET   WAS    WAS    2018  2017-10-20              8             14   \n",
       "...    ...   ...    ...     ...         ...            ...            ...   \n",
       "8350   PHI   PHO    PHO    2024  2024-03-20              5             24   \n",
       "8351   UTA   OKC    OKC    2024  2024-03-20             18             16   \n",
       "8352   IND   DET    IND    2024  2024-03-20              7              8   \n",
       "8353   MIL   BOS    BOS    2024  2024-03-20             10              2   \n",
       "8354   LAC   POR    LAC    2024  2024-03-20             22             17   \n",
       "\n",
       "      mp_cumulative_team0  mp_cumulative_team1  fg_cumulative_team0  ...  \\\n",
       "0              240.000000           240.000000            42.000000  ...   \n",
       "1              240.000000           240.000000            44.000000  ...   \n",
       "2              240.000000           240.000000            43.000000  ...   \n",
       "3              240.000000           240.000000            37.500000  ...   \n",
       "4              240.000000           240.000000            41.000000  ...   \n",
       "...                   ...                  ...                  ...  ...   \n",
       "8350           240.735294           241.470588            41.455882  ...   \n",
       "8351           241.838235           241.515152            42.588235  ...   \n",
       "8352           240.367647           241.102941            46.382353  ...   \n",
       "8353           241.119403           241.838235            43.268657  ...   \n",
       "8354           240.373134           242.985075            42.507463  ...   \n",
       "\n",
       "      stl%_cumulative_team1  blk%_cumulative_team0  blk%_cumulative_team1  \\\n",
       "0                  5.100000              10.500000               5.300000   \n",
       "1                 10.600000              11.300000              14.100000   \n",
       "2                  6.200000              12.700000               2.900000   \n",
       "3                  5.800000               5.100000               8.000000   \n",
       "4                  7.700000               7.000000              17.200000   \n",
       "...                     ...                    ...                    ...   \n",
       "8350               7.380882              10.872059              10.926471   \n",
       "8351               8.290909              10.625000              12.915152   \n",
       "8352               6.185294               9.545588               8.539706   \n",
       "8353               6.738235               8.637313              11.938235   \n",
       "8354               7.995522               9.485075               8.408955   \n",
       "\n",
       "      tov%_cumulative_team0  tov%_cumulative_team1  ortg_cumulative_team0  \\\n",
       "0                 15.500000              13.600000             103.900000   \n",
       "1                 13.500000              10.800000             125.600000   \n",
       "2                 12.000000              15.600000             110.300000   \n",
       "3                  9.950000              14.400000             100.950000   \n",
       "4                  7.300000               7.300000             103.600000   \n",
       "...                     ...                    ...                    ...   \n",
       "8350              10.083824              12.583824             117.983824   \n",
       "8351              12.877941              10.440909             117.452941   \n",
       "8352              10.958824              13.114706             120.725000   \n",
       "8353              10.864179              10.339706             119.949254   \n",
       "8354              11.274627              12.708955             120.468657   \n",
       "\n",
       "      ortg_cumulative_team1  drtg_cumulative_team0  drtg_cumulative_team1  \\\n",
       "0                112.600000             109.100000             118.700000   \n",
       "1                123.600000              77.000000             115.700000   \n",
       "2                115.700000             103.600000             123.600000   \n",
       "3                110.300000             106.550000             115.100000   \n",
       "4                115.100000              91.400000             110.300000   \n",
       "...                     ...                    ...                    ...   \n",
       "8350             118.973529             115.505882             116.622059   \n",
       "8351             121.086364             120.983824             113.606061   \n",
       "8352             111.780882             119.098529             120.054412   \n",
       "8353             124.129412             116.650746             112.086765   \n",
       "8354             110.244776             116.623881             118.516418   \n",
       "\n",
       "      team1_winner  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                1  \n",
       "...            ...  \n",
       "8350             1  \n",
       "8351             1  \n",
       "8352             0  \n",
       "8353             1  \n",
       "8354             0  \n",
       "\n",
       "[8355 rows x 72 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df  = pd.read_csv('csvs/cumulative_averages.csv')\n",
    "drop_extraneous_col(training_df)\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataframe into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "undesired_columns = ['team0', 'team1', 'winner', 'season', 'date', 'team1_winner']\n",
    "# We decided to train from the 2018 season to the 2023 season\n",
    "training_seasons = [2018,2019,2020,2021,2022,2023]\n",
    "# Splitting the dataframe into train and test\n",
    "X_train = training_df[training_df['season'].isin(training_seasons)].drop(undesired_columns, axis=1)\n",
    "X_test = training_df[training_df['season'] == 2024].drop(undesired_columns, axis=1)\n",
    "y_train = training_df[training_df['season'].isin(training_seasons)]['team1_winner']\n",
    "y_test = training_df[training_df['season'] == 2024]['team1_winner']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in X_train: 7348\n",
      "Observations in y_train: 7348\n",
      "Observations in X_test: 1007\n",
      "Observations in y_test: 1007\n"
     ]
    }
   ],
   "source": [
    "# Double checking the shapes of the training and testing dataframes\n",
    "\n",
    "print(f'Observations in X_train: {X_train.shape[0]}')\n",
    "print(f'Observations in y_train: {y_train.shape[0]}')\n",
    "\n",
    "print(f'Observations in X_test: {X_test.shape[0]}')\n",
    "print(f'Observations in y_test: {y_test.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scalar = StandardScaler()\n",
    "X_train = std_scalar.fit_transform(X_train)\n",
    "X_test = std_scalar.fit_transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Type of Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the type of cross validation\n",
    "tscv = TimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Results DataFrame to Store Training and Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Model', 'Training Accuracy', 'Validation Accuracy',\n",
    "                             'Training Precision', 'Validation Precision',\n",
    "                             'Training Recall ', 'Validation Recall',\n",
    "                             'Training F1', 'Validation F1',\n",
    "                             'Training ROC_AUC', 'Validation ROC_AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephlim/Documents/3B/MSCI 446/MSCI-446-Project/env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/josephlim/Documents/3B/MSCI 446/MSCI-446-Project/env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/josephlim/Documents/3B/MSCI 446/MSCI-446-Project/env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the Logistic Regresion Model\n",
    "model_lr = LogisticRegression(solver='saga', max_iter=5000, random_state=42)\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_lr = RFECV(estimator = model_lr, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_lr.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_lr.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(estimator=model_lr, param_grid=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "grid_search_lr.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_lr = grid_search_lr.cv_results_\n",
    "\n",
    "new_row_data = ['Logistic Regression']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_lr[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_lr[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_lr[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the RandomForestClassifier Model\n",
    "model_rfc = RandomForestClassifier(random_state=42)\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_rfc = RFECV(estimator = model_rfc, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_rfc.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_rfc.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],       # Number of trees in the forest.\n",
    "    'max_depth': [None, 10, 20, 30],        # Maximum depth of the tree.\n",
    "    'min_samples_split': [2, 5, 10],        # Minimum number of samples required to split an internal node.\n",
    "    'min_samples_leaf': [1, 2, 4], \n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "random_search_rfc = RandomizedSearchCV(estimator=model_rfc, n_iter=100, param_distributions=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "random_search_rfc.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_rfc = random_search_rfc.cv_results_\n",
    "\n",
    "new_row_data = ['Random Forest Classifier']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_rfc[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_rfc[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_rfc[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the XGB Classifier Model\n",
    "model_xgb = XGBClassifier(objective='binary:logistic')\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_xgb = RFECV(estimator = model_xgb, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_xgb.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_xgb.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'min_child_weight': [1, 3, 5, 7]\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(estimator=model_xgb, n_iter=100, param_distributions=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "random_search_xgb.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_xgb = random_search_xgb.cv_results_\n",
    "\n",
    "new_row_data = ['XGB Classifier']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_xgb[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_xgb[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_xgb[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the Ridge Classifier Model\n",
    "model_rc = RidgeClassifier(solver='saga', max_iter=5000, random_state=42)\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_rc = RFECV(estimator = model_rc, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_rc.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_rc.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "grid_search_rc = GridSearchCV(estimator=model_rc, param_grid=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "grid_search_rc.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_rc = grid_search_rc.cv_results_\n",
    "\n",
    "new_row_data = ['Ridge Classifier']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_rc[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_rc[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_rc[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the Support Vector Machine Model\n",
    "model_svm = SVC(kernel='linear', random_state=42)\n",
    "# Define the Recursive Feature Elimination Cross Validation\n",
    "model_rfecv_svm = RFECV(estimator = model_svm, cv=tscv, min_features_to_select=30, scoring='accuracy')\n",
    "# Fitting the rfecv model to the data\n",
    "model_rfecv_svm.fit(X_train, y_train)\n",
    "# Transforming the the training dataset to only have the selected features\n",
    "X_train_selected = model_rfecv_svm.transform(X_train)\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient\n",
    "}\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(estimator=model_svm, param_grid=param_grid, cv=tscv, scoring=scoring, refit='accuracy', verbose=1, return_train_score=True)\n",
    "grid_search_svm.fit(X_train_selected,y_train)\n",
    "\n",
    "cv_results_svm = grid_search_svm.cv_results_\n",
    "\n",
    "new_row_data = ['Support Vector Machine']\n",
    "for scorer in scoring:\n",
    "    best_validation_score = cv_results_svm[f'mean_test_{scorer}'].max()\n",
    "    i = list(cv_results_svm[f'mean_test_{scorer}']).index(best_validation_score)\n",
    "    train_score = list(cv_results_svm[f'mean_train_{scorer}'])[i]\n",
    "    new_row_data.extend([train_score,best_validation_score])\n",
    "\n",
    "new_row_series = pd.Series(new_row_data, index=results_df.columns)\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_series).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Validation Precision</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Validation Recall</th>\n",
       "      <th>Training F1</th>\n",
       "      <th>Validation F1</th>\n",
       "      <th>Training ROC_AUC</th>\n",
       "      <th>Validation ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.658739</td>\n",
       "      <td>0.631046</td>\n",
       "      <td>0.671274</td>\n",
       "      <td>0.660882</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.891235</td>\n",
       "      <td>0.736237</td>\n",
       "      <td>0.7197</td>\n",
       "      <td>0.632698</td>\n",
       "      <td>0.617954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Training Accuracy Validation Accuracy  \\\n",
       "0  Logistic Regression          0.658739            0.631046   \n",
       "\n",
       "  Training Precision Validation Precision Training Recall  Validation Recall  \\\n",
       "0           0.671274             0.660882           0.8988          0.891235   \n",
       "\n",
       "  Training F1 Validation F1 Training ROC_AUC Validation ROC_AUC  \n",
       "0    0.736237        0.7197         0.632698           0.617954  "
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the Best Performing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Evaulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
